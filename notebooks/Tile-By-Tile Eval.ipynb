{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor, default_argument_parser, default_setup\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "from deepent.data.register_datasets import register_datasets\n",
    "from deepent.config import add_deepent_config\n",
    "from tools.vis import visualize_single\n",
    "from tools.train_net import *\n",
    "from tools.predictor import RGBDPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../configs/deepent_fuse_rcnn_R_50_FPN.yaml'\n",
    "threshold = 0.5\n",
    "model = '../output/baseline_fuse_07_02_2020/model_0089999.pth'\n",
    "samples = 1\n",
    "dataset = 'CPT2a-n_train'\n",
    "type_ = 'many'\n",
    "opts = []\n",
    "\n",
    "class Cfg_Args:\n",
    "    def __init__(self, conf, tr, mod, sam, ty, opt, dts):\n",
    "        self.config_file = conf\n",
    "        self.threshold = tr\n",
    "        self.model = mod\n",
    "        self.samples = sam\n",
    "        self.dataset = dts\n",
    "        self.type = ty\n",
    "        self.opts = []\n",
    "        self.output = None\n",
    "        \n",
    "args = Cfg_Args(config_file, threshold, model, samples, type_, opts, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:16 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[03/19 01:30:17 detectron2]: \u001b[0mEnvironment info:\n",
      "------------------------  --------------------------------------------------------------------------------------\n",
      "sys.platform              linux\n",
      "Python                    3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) [GCC 7.2.0]\n",
      "numpy                     1.15.4\n",
      "detectron2                0.1.1 @/home/ubuntu/drone-tree-id/lib/detectron2/detectron2\n",
      "detectron2 compiler       GCC 5.4\n",
      "detectron2 CUDA compiler  10.1\n",
      "detectron2 arch flags     sm_75\n",
      "DETECTRON2_ENV_MODULE     <not set>\n",
      "PyTorch                   1.4.0 @/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch\n",
      "PyTorch debug build       False\n",
      "CUDA available            True\n",
      "GPU 0                     Tesla T4\n",
      "CUDA_HOME                 /usr/local/cuda-10.1\n",
      "NVCC                      Cuda compilation tools, release 10.1, V10.1.243\n",
      "Pillow                    5.4.1\n",
      "torchvision               0.5.0 @/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision\n",
      "torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75\n",
      "cv2                       4.1.1\n",
      "------------------------  --------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2018.0.3 Product Build 20180406 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[03/19 01:30:17 detectron2]: \u001b[0mCommand line arguments: <__main__.Cfg_Args object at 0x7f1b56fda470>\n",
      "\u001b[32m[03/19 01:30:17 detectron2]: \u001b[0mContents of args.config_file=../configs/deepent_fuse_rcnn_R_50_FPN.yaml:\n",
      "_BASE_: \"Base-DeepEnt-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  MASK_ON: True\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "  PIXEL_MEAN: [120.961, 125.623, 111.1, 82.9653]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0, 1.0]\n",
      "SOLVER:\n",
      "  IMS_PER_BATCH: 2 #16\n",
      "\n",
      "\u001b[32m[03/19 01:30:17 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 4\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('Kelowna_test', 'CPT2a-n_test', 'CPT2b_test', 'SALCT1_test', 'AMECT9_test')\n",
      "  TRAIN: ('Kelowna_train', 'CPT2a-n_train', 'CPT2b_train', 'SALCT1_train', 'AMECT9_train')\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: RGBA\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (600, 640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_deepent_fpn_backbone\n",
      "  DEPTH_ENCODER:\n",
      "    FREEZE_AT: 0\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: True\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [120.961, 125.623, 111.1, 82.9653]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.5\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: ../output/baseline_fuse_07_02_2020/model_0089999.pth\n",
      "OUTPUT_DIR: ./output\n",
      "SEED: 24\n",
      "SOLVER:\n",
      "  BASE_LR: 0.001\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 2\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 120000\n",
      "  MOMENTUM: 0.9\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:17 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "add_deepent_config(cfg)\n",
    "cfg.merge_from_file(config_file)\n",
    "cfg.merge_from_list(opts)\n",
    "cfg.MODEL.WEIGHTS = model \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold \n",
    "cfg.freeze()\n",
    "default_setup(cfg, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_array = ['--eval-only',\n",
    "             '--config-file', '/home/ubuntu/drone-tree-id/configs/deepent_fuse_rcnn_R_50_FPN.yaml',\n",
    "             'OUTPUT_DIR',' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ ',\n",
    "             'MODEL.WEIGHTS', '/home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/model_final.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering Kelowna_train\n",
      "Registering AMECT9_train\n",
      "Registering SALCT1_train\n",
      "Registering CPT2b_train\n",
      "Registering CPT2a-n_train\n",
      "Registering temporary_0_test\n",
      "Registering temporary_4_test\n",
      "Registering temporary_8_test\n",
      "Registering temporary_7_test\n",
      "Registering Kelowna_test\n",
      "Registering AMECT9_test\n",
      "Registering temporary_2_test\n",
      "Registering SALCT1_test\n",
      "Registering CPT2b_test\n",
      "Registering temporary_1_test\n",
      "Registering temporary_9_test\n",
      "Registering temporary_6_test\n",
      "Registering temporary_5_test\n",
      "Registering temporary_3_test\n",
      "Registering CPT2a-n_test\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mEnvironment info:\n",
      "------------------------  --------------------------------------------------------------------------------------\n",
      "sys.platform              linux\n",
      "Python                    3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) [GCC 7.2.0]\n",
      "numpy                     1.15.4\n",
      "detectron2                0.1.1 @/home/ubuntu/drone-tree-id/lib/detectron2/detectron2\n",
      "detectron2 compiler       GCC 5.4\n",
      "detectron2 CUDA compiler  10.1\n",
      "detectron2 arch flags     sm_75\n",
      "DETECTRON2_ENV_MODULE     <not set>\n",
      "PyTorch                   1.4.0 @/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch\n",
      "PyTorch debug build       False\n",
      "CUDA available            True\n",
      "GPU 0                     Tesla T4\n",
      "CUDA_HOME                 /usr/local/cuda-10.1\n",
      "NVCC                      Cuda compilation tools, release 10.1, V10.1.243\n",
      "Pillow                    5.4.1\n",
      "torchvision               0.5.0 @/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision\n",
      "torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75\n",
      "cv2                       4.1.1\n",
      "------------------------  --------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2018.0.3 Product Build 20180406 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mEnvironment info:\n",
      "------------------------  --------------------------------------------------------------------------------------\n",
      "sys.platform              linux\n",
      "Python                    3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) [GCC 7.2.0]\n",
      "numpy                     1.15.4\n",
      "detectron2                0.1.1 @/home/ubuntu/drone-tree-id/lib/detectron2/detectron2\n",
      "detectron2 compiler       GCC 5.4\n",
      "detectron2 CUDA compiler  10.1\n",
      "detectron2 arch flags     sm_75\n",
      "DETECTRON2_ENV_MODULE     <not set>\n",
      "PyTorch                   1.4.0 @/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch\n",
      "PyTorch debug build       False\n",
      "CUDA available            True\n",
      "GPU 0                     Tesla T4\n",
      "CUDA_HOME                 /usr/local/cuda-10.1\n",
      "NVCC                      Cuda compilation tools, release 10.1, V10.1.243\n",
      "Pillow                    5.4.1\n",
      "torchvision               0.5.0 @/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision\n",
      "torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75\n",
      "cv2                       4.1.1\n",
      "------------------------  --------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - Intel(R) Math Kernel Library Version 2018.0.3 Product Build 20180406 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CUDA Runtime 10.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.1\n",
      "  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/ubuntu/drone-tree-id/configs/deepent_fuse_rcnn_R_50_FPN.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ ', 'MODEL.WEIGHTS', '/home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/model_final.pth'], resume=False)\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='/home/ubuntu/drone-tree-id/configs/deepent_fuse_rcnn_R_50_FPN.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ ', 'MODEL.WEIGHTS', '/home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/model_final.pth'], resume=False)\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mContents of args.config_file=/home/ubuntu/drone-tree-id/configs/deepent_fuse_rcnn_R_50_FPN.yaml:\n",
      "_BASE_: \"Base-DeepEnt-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  MASK_ON: True\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "  PIXEL_MEAN: [120.961, 125.623, 111.1, 82.9653]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0, 1.0]\n",
      "SOLVER:\n",
      "  IMS_PER_BATCH: 2 #16\n",
      "\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mContents of args.config_file=/home/ubuntu/drone-tree-id/configs/deepent_fuse_rcnn_R_50_FPN.yaml:\n",
      "_BASE_: \"Base-DeepEnt-RCNN-FPN.yaml\"\n",
      "MODEL:\n",
      "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
      "  MASK_ON: True\n",
      "  RESNETS:\n",
      "    DEPTH: 50\n",
      "  PIXEL_MEAN: [120.961, 125.623, 111.1, 82.9653]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0, 1.0]\n",
      "SOLVER:\n",
      "  IMS_PER_BATCH: 2 #16\n",
      "\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 4\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ['temporary_0_test', 'temporary_1_test', 'temporary_2_test', 'temporary_3_test', 'temporary_4_test', 'temporary_5_test', 'temporary_6_test', 'temporary_7_test', 'temporary_8_test', 'temporary_9_test']\n",
      "  TRAIN: ('Kelowna_train', 'CPT2a-n_train', 'CPT2b_train', 'SALCT1_train', 'AMECT9_train')\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: RGBA\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (600, 640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_deepent_fpn_backbone\n",
      "  DEPTH_ENCODER:\n",
      "    FREEZE_AT: 0\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: True\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [120.961, 125.623, 111.1, 82.9653]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: /home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/model_final.pth\n",
      "OUTPUT_DIR:  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ \n",
      "SEED: 24\n",
      "SOLVER:\n",
      "  BASE_LR: 0.001\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 2\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 120000\n",
      "  MOMENTUM: 0.9\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 4\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ['temporary_0_test', 'temporary_1_test', 'temporary_2_test', 'temporary_3_test', 'temporary_4_test', 'temporary_5_test', 'temporary_6_test', 'temporary_7_test', 'temporary_8_test', 'temporary_9_test']\n",
      "  TRAIN: ('Kelowna_train', 'CPT2a-n_train', 'CPT2b_train', 'SALCT1_train', 'AMECT9_train')\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: RGBA\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (600, 640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_deepent_fpn_backbone\n",
      "  DEPTH_ENCODER:\n",
      "    FREEZE_AT: 0\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: True\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [120.961, 125.623, 111.1, 82.9653]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 50\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 80\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: /home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/model_final.pth\n",
      "OUTPUT_DIR:  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ \n",
      "SEED: 24\n",
      "SOLVER:\n",
      "  BASE_LR: 0.001\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 2\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 120000\n",
      "  MOMENTUM: 0.9\n",
      "  STEPS: (60000, 80000)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mFull config saved to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /config.yaml\n",
      "\u001b[32m[03/19 01:30:27 detectron2]: \u001b[0mFull config saved to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /config.yaml\n",
      "\u001b[32m[03/19 01:30:31 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): FusedResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (depth_encoder): DepthEncoder(\n",
      "        (stem): BasicStem(\n",
      "          (conv1): Conv2d(\n",
      "            1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (res2): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (shortcut): Conv2d(\n",
      "              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv1): Conv2d(\n",
      "              64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (res3): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (shortcut): Conv2d(\n",
      "              256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv1): Conv2d(\n",
      "              256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (3): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (res4): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (shortcut): Conv2d(\n",
      "              512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "            (conv1): Conv2d(\n",
      "              512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (3): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (4): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (5): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (res5): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (shortcut): Conv2d(\n",
      "              1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "            )\n",
      "            (conv1): Conv2d(\n",
      "              1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_res2): LateralFuser(\n",
      "        (fuse_out): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_res3): LateralFuser(\n",
      "        (fuse_out): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_res4): LateralFuser(\n",
      "        (fuse_out): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_res5): LateralFuser(\n",
      "        (fuse_out): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:31 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): FusedResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (depth_encoder): DepthEncoder(\n",
      "        (stem): BasicStem(\n",
      "          (conv1): Conv2d(\n",
      "            1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (res2): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (shortcut): Conv2d(\n",
      "              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv1): Conv2d(\n",
      "              64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (res3): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (shortcut): Conv2d(\n",
      "              256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv1): Conv2d(\n",
      "              256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (3): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (res4): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (shortcut): Conv2d(\n",
      "              512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "            (conv1): Conv2d(\n",
      "              512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (3): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (4): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (5): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (res5): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (shortcut): Conv2d(\n",
      "              1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "            )\n",
      "            (conv1): Conv2d(\n",
      "              1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2d(\n",
      "              2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv2): Conv2d(\n",
      "              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "            )\n",
      "            (conv3): Conv2d(\n",
      "              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_res2): LateralFuser(\n",
      "        (fuse_out): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_res3): LateralFuser(\n",
      "        (fuse_out): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_res4): LateralFuser(\n",
      "        (fuse_out): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fuse_res5): LateralFuser(\n",
      "        (fuse_out): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:31 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from /home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/model_final.pth\n",
      "\u001b[32m[03/19 01:30:31 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from /home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/model_final.pth\n",
      "\u001b[32m[03/19 01:30:31 fvcore.common.checkpoint]: \u001b[0mSome model parameters are not in the checkpoint:\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res2.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res3.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res4.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res5.fuse_out.{weight, bias}\u001b[0m\n",
      "\u001b[32m[03/19 01:30:31 fvcore.common.checkpoint]: \u001b[0mSome model parameters are not in the checkpoint:\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res2.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res3.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res4.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res5.fuse_out.{weight, bias}\u001b[0m\n",
      "\u001b[32m[03/19 01:30:31 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 7            |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 7            |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:31 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 7            |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 7            |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:31 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:31 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[03/19 01:30:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:31 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_0_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:31 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_0_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:31 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_0_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:31 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_0_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[03/19 01:30:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 1/1. 0.5701 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 1/1. 0.5701 s / img. ETA=0:00:00\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.677252 (0.677252 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.677252 (0.677252 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.570134 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.570134 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.320\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 6.425 | 11.985 | 8.155  | 0.000 | 0.000 | 9.768 |\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 6.425 | 11.985 | 8.155  | 0.000 | 0.000 | 9.768 |\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 6.425 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 6.425 | dead       | nan  | deciduous  | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.022\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.120\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.043\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.200\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 2.209 | 11.985 | 0.391  | 0.000 | 0.000 | 3.999 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 2.209 | 11.985 | 0.391  | 0.000 | 0.000 | 3.999 |\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 2.209 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 2.209 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: 6.4252,11.9854,8.1553,0.0000,0.0000,9.7680\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: 6.4252,11.9854,8.1553,0.0000,0.0000,9.7680\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: 2.2095,11.9854,0.3908,0.0000,0.0000,3.9989\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.testing]: \u001b[0mcopypaste: 2.2095,11.9854,0.3908,0.0000,0.0000,3.9989\n",
      "\u001b[32m[03/19 01:30:32 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 8            |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 8            |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:32 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 8            |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 8            |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:32 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:32 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[32m[03/19 01:30:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.00 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_1_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:32 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_1_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:32 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_1_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:32 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_1_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.265216 (0.265216 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.265216 (0.265216 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.165974 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.165974 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.052\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.300\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 5.245 | 21.700 | 2.600  |  nan  | 0.000 | 6.312 |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 5.245 | 21.700 | 2.600  |  nan  | 0.000 | 6.312 |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 5.245 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 5.245 | dead       | nan  | deciduous  | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.073\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.027\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.125\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.143\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 2.261 | 7.341  | 0.000  |  nan  | 0.000 | 2.690 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 2.261 | 7.341  | 0.000  |  nan  | 0.000 | 2.690 |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 2.261 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 2.261 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: 5.2453,21.6997,2.6003,nan,0.0000,6.3121\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: 5.2453,21.6997,2.6003,nan,0.0000,6.3121\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: 2.2607,7.3407,0.0000,nan,0.0000,2.6898\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: 2.2607,7.3407,0.0000,nan,0.0000,2.6898\n",
      "\u001b[32m[03/19 01:30:33 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 53           |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 53           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:33 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 53           |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 53           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:33 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:33 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[03/19 01:30:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_2_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_2_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:33 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_2_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:33 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_2_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.260942 (0.260942 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.260942 (0.260942 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.163139 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.163139 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.297 | 0.990  | 0.000  |  nan  | 0.891 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.297 | 0.990  | 0.000  |  nan  | 0.891 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.297 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.297 | dead       | nan  | deciduous  | nan  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.495 | 0.990  | 0.000  |  nan  | 1.485 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.495 | 0.990  | 0.000  |  nan  | 1.485 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.495 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.495 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: 0.2970,0.9901,0.0000,nan,0.8911,0.0000\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: 0.2970,0.9901,0.0000,nan,0.8911,0.0000\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: 0.4950,0.9901,0.0000,nan,1.4851,0.0000\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.testing]: \u001b[0mcopypaste: 0.4950,0.9901,0.0000,nan,1.4851,0.0000\n",
      "\u001b[32m[03/19 01:30:33 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 31           |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 31           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:33 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 31           |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 31           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:33 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:33 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[03/19 01:30:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_3_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:33 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_3_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:33 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_3_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:33 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_3_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.229140 (0.229140 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.229140 (0.229140 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.159184 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.159184 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.020\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.050\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.396 | 1.980  | 0.000  | 0.000 | 0.000 | 1.379 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.396 | 1.980  | 0.000  | 0.000 | 0.000 | 1.379 |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.396 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.396 | dead       | nan  | deciduous  | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.025\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.113 | 0.566  | 0.000  | 0.000 | 0.000 | 0.368 |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.113 | 0.566  | 0.000  | 0.000 | 0.000 | 0.368 |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.113 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.113 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: 0.3960,1.9802,0.0000,0.0000,0.0000,1.3791\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: 0.3960,1.9802,0.0000,0.0000,0.0000,1.3791\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: 0.1132,0.5658,0.0000,0.0000,0.0000,0.3678\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: 0.1132,0.5658,0.0000,0.0000,0.0000,0.3678\n",
      "\u001b[32m[03/19 01:30:34 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 82           |    dead    | 0            | deciduous  | 3            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 85           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:34 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 82           |    dead    | 0            | deciduous  | 3            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 85           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:34 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:34 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
      "\u001b[32m[03/19 01:30:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_4_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_4_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:34 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_4_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:34 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_4_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.276871 (0.276871 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.276871 (0.276871 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.168167 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.168167 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.055 | 0.495  | 0.000  |  nan  | 0.189 |  nan  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.055 | 0.495  | 0.000  |  nan  | 0.189 |  nan  |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP    |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:------|\n",
      "| coniferous | 0.110 | dead       | nan  | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP    |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:------|\n",
      "| coniferous | 0.110 | dead       | nan  | deciduous  | 0.000 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.089 | 0.552  | 0.000  |  nan  | 0.209 |  nan  |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.089 | 0.552  | 0.000  |  nan  | 0.209 |  nan  |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP    |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:------|\n",
      "| coniferous | 0.178 | dead       | nan  | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP    |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:------|\n",
      "| coniferous | 0.178 | dead       | nan  | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0552,0.4950,0.0000,nan,0.1886,nan\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0552,0.4950,0.0000,nan,0.1886,nan\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0891,0.5516,0.0000,nan,0.2087,nan\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0891,0.5516,0.0000,nan,0.2087,nan\n",
      "\u001b[32m[03/19 01:30:34 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 41           |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 41           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:34 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 41           |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 41           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:34 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:34 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[03/19 01:30:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_5_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:34 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_5_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:34 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_5_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:34 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_5_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.220037 (0.220037 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.220037 (0.220037 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.154413 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.154413 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  | 0.000 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  | 0.000 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.000 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.000 | dead       | nan  | deciduous  | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  | 0.000 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  | 0.000 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.000 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.000 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,0.0000,0.0000\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,0.0000,0.0000\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,0.0000,0.0000\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,0.0000,0.0000\n",
      "\u001b[32m[03/19 01:30:35 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 55           |    dead    | 0            | deciduous  | 4            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 59           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:35 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 55           |    dead    | 0            | deciduous  | 4            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 59           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:35 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:35 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
      "\u001b[32m[03/19 01:30:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_6_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_6_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:35 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_6_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:35 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_6_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.241139 (0.241139 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.241139 (0.241139 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.160586 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.160586 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.045 | 0.090  | 0.000  | 0.000 | 0.743 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.045 | 0.090  | 0.000  | 0.000 | 0.743 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP    |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:------|\n",
      "| coniferous | 0.090 | dead       | nan  | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP    |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:------|\n",
      "| coniferous | 0.090 | dead       | nan  | deciduous  | 0.000 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.027 | 0.090  | 0.000  | 0.000 | 0.223 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.027 | 0.090  | 0.000  | 0.000 | 0.223 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP    |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:------|\n",
      "| coniferous | 0.054 | dead       | nan  | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP    |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:------|\n",
      "| coniferous | 0.054 | dead       | nan  | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0450,0.0900,0.0000,0.0000,0.7426,0.0000\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0450,0.0900,0.0000,0.0000,0.7426,0.0000\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0270,0.0900,0.0000,0.0000,0.2228,0.0000\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0270,0.0900,0.0000,0.0000,0.2228,0.0000\n",
      "\u001b[32m[03/19 01:30:35 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 66           |    dead    | 1            | deciduous  | 1            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 68           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:35 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 66           |    dead    | 1            | deciduous  | 1            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 68           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:35 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:35 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_7_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:35 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_7_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:35 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_7_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:35 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_7_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.255138 (0.255138 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.255138 (0.255138 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.165186 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.165186 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  | 0.000 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  | 0.000 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
      "| coniferous | 0.000 | dead       | 0.000 | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
      "| coniferous | 0.000 | dead       | 0.000 | deciduous  | 0.000 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  | 0.000 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  |  nan  | 0.000 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
      "| coniferous | 0.000 | dead       | 0.000 | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
      "| coniferous | 0.000 | dead       | 0.000 | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,0.0000,0.0000\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,0.0000,0.0000\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,0.0000,0.0000\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,0.0000,0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:36 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 24           |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 24           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:36 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 24           |    dead    | 0            | deciduous  | 0            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 24           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:36 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:36 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[03/19 01:30:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_8_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:36 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_8_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:36 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_8_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:36 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_8_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.268288 (0.268288 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.268288 (0.268288 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.167088 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.167088 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.065 | 0.215  | 0.000  |  nan  | 0.495 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.065 | 0.215  | 0.000  |  nan  | 0.495 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.065 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.065 | dead       | nan  | deciduous  | nan  |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.043 | 0.215  | 0.000  |  nan  | 0.248 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.043 | 0.215  | 0.000  |  nan  | 0.248 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.043 | dead       | nan  | deciduous  | nan  |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP   | category   | AP   |\n",
      "|:-----------|:------|:-----------|:-----|:-----------|:-----|\n",
      "| coniferous | 0.043 | dead       | nan  | deciduous  | nan  |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0646,0.2152,0.0000,nan,0.4950,0.0000\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0646,0.2152,0.0000,nan,0.4950,0.0000\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0430,0.2152,0.0000,nan,0.2475,0.0000\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0430,0.2152,0.0000,nan,0.2475,0.0000\n",
      "\u001b[32m[03/19 01:30:37 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 26           |    dead    | 1            | deciduous  | 2            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 29           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:37 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "| coniferous | 26           |    dead    | 1            | deciduous  | 2            |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 29           |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[03/19 01:30:37 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:37 d2.data.common]: \u001b[0mSerializing 1 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/19 01:30:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[32m[03/19 01:30:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_9_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'temporary_9_test'. Trying to convert it to COCO format ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:37 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_9_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/19 01:30:37 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at ' home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/temporary_9_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 1 images\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.236062 (0.236062 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.236062 (0.236062 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.160077 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.160077 s / img per device, on 1 devices)\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to  home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/ /inference/coco_instances_results.json\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.01s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
      "| coniferous | 0.000 | dead       | 0.000 | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
      "| coniferous | 0.000 | dead       | 0.000 | deciduous  | 0.000 |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.025 | 0.083  | 0.000  | 0.000 | 0.495 | 0.000 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.025 | 0.083  | 0.000  | 0.000 | 0.495 | 0.000 |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
      "| coniferous | 0.074 | dead       | 0.000 | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP    | category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
      "| coniferous | 0.074 | dead       | 0.000 | deciduous  | 0.000 |\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0248,0.0825,0.0000,0.0000,0.4950,0.0000\n",
      "\u001b[32m[03/19 01:30:37 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0248,0.0825,0.0000,0.0000,0.4950,0.0000\n",
      "\u001b[32m[03/19 01:30:39 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from /home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/model_final.pth\n",
      "\u001b[32m[03/19 01:30:39 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from /home/ubuntu/drone-tree-id/output/baseline_fuse_07_02_2020/model_final.pth\n",
      "\u001b[32m[03/19 01:30:39 fvcore.common.checkpoint]: \u001b[0mSome model parameters are not in the checkpoint:\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res2.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res3.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res4.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res5.fuse_out.{weight, bias}\u001b[0m\n",
      "\u001b[32m[03/19 01:30:39 fvcore.common.checkpoint]: \u001b[0mSome model parameters are not in the checkpoint:\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res2.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res3.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res4.fuse_out.{weight, bias}\u001b[0m\n",
      "  \u001b[34mbackbone.bottom_up.fuse_res5.fuse_out.{weight, bias}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def ind_eval(args):\n",
    "    #create new mini-datasets\n",
    "    test_tiles = []\n",
    "    test_tile_segs = []\n",
    "    for location in glob.glob('/home/ubuntu/RGBD-Tree-Segs-Clean/test/*'):\n",
    "        filenames = glob.glob(location + '/*.png')\n",
    "        with open(os.path.join(location,'segs.json'),'r') as segfile:\n",
    "            segs = json.load(segfile)\n",
    "            for ind in np.random.randint(0,len(filenames),2):\n",
    "                test_tiles.append(filenames[ind])\n",
    "                test_tile_segs.append(list(filter(lambda x : x[\"file_name\"]==filenames[ind],segs)))\n",
    "                \n",
    "    test_dir = '/home/ubuntu/RGBD-Tree-Segs-Clean/test/'                \n",
    "    folder_names = []                 \n",
    "    for i,path in enumerate(test_tiles):\n",
    "        folder_names.append('temporary_'+str(i))\n",
    "        os.mkdir(test_dir + folder_names[-1])\n",
    "        shutil.copy(path, test_dir + folder_names[-1] + '/' + path.split('/')[-1])\n",
    "        with open(os.path.join(test_dir,folder_names[-1],'segs.json'),'w') as segfile:\n",
    "            segfile.write(json.dumps(test_tile_segs[i]))\n",
    "    test_set_names = list(map(lambda x : x + \"_test\", folder_names))        \n",
    "    register_datasets(f'/home/ubuntu/RGBD-Tree-Segs-Clean/')\n",
    "    \n",
    "    cfg = get_cfg()\n",
    "    add_deepent_config(cfg)\n",
    "    cfg.merge_from_file(args.config_file)\n",
    "    cfg.merge_from_list(args.opts)\n",
    "    cfg.DATASETS.TEST = test_set_names\n",
    "    cfg.freeze()\n",
    "    default_setup(cfg, args)\n",
    "    \n",
    "    #Run Eval\n",
    "    model = Trainer.build_model(cfg)\n",
    "    DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n",
    "        cfg.MODEL.WEIGHTS, resume=args.resume\n",
    "    )\n",
    "    res = Trainer.test(cfg, model,wandb_on=False)\n",
    "    if comm.is_main_process():\n",
    "                verify_results(cfg, res)\n",
    "        \n",
    "    #Visualize with different models and show evals\n",
    "    predictor = RGBDPredictor(cfg)\n",
    "    fig,axes = plt.subplots(10,1,figsize=(70,70))\n",
    "    ax = axes.ravel()\n",
    "    for i,test_set_name in enumerate(test_set_names):\n",
    "        data = list(DatasetCatalog.get(test_set_name))\n",
    "        metadata = MetadataCatalog.get(test_set_name)\n",
    "        dic=data[0]\n",
    "        rgba = cv2.imread(dic[\"file_name\"], cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.imread(dic[\"file_name\"])\n",
    "        predictions = predictor(rgba)\n",
    "        visualizer = Visualizer(img, metadata=metadata)\n",
    "        vis = visualizer.draw_instance_predictions(predictions[\"instances\"].to(\"cpu\")).get_image()\n",
    "        name = res[test_set_name][\"segm\"][\"AP\"]\n",
    "        ax[i].set_title(\"AP: \" + str(name))\n",
    "        ax[i].axis('off')\n",
    "        ax[i].imshow(vis)\n",
    "        \n",
    "    #remove temporary dirs\n",
    "    os.chdir('/home/ubuntu/RGBD-Tree-Segs-Clean/test')\n",
    "    for folder in glob.glob('temporary*'):\n",
    "        for file in glob.glob(folder + '/*'):\n",
    "            os.remove(file)\n",
    "        os.rmdir(folder)   \n",
    "        \n",
    "    return res\n",
    "\n",
    "args = default_argument_parser().parse_args(arg_array)\n",
    "results = ind_eval(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\" + results[\"temporary_0_test\"][\"segm\"][\"AP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove temporary dirs\n",
    "os.chdir('/home/ubuntu/RGBD-Tree-Segs-Clean/test')\n",
    "for folder in glob.glob('temporary*'):\n",
    "    for file in glob.glob(folder + '/*'):\n",
    "        os.remove(file)\n",
    "    os.rmdir(folder)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
